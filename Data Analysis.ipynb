{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Things to get from data\n",
    "1. time tkane for introduction trial ([4,2,3,5,1])\n",
    "2. time taken for each imitation trial\n",
    "3. initial states, sequence of comparison, final state for each test trial\n",
    "4. choices for demo trials\n",
    "5. initial states, sequence of comparison, final state for each demo trial\n",
    "6. description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import glob \n",
    "import os \n",
    "import csv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_up='C:/Users/guoqi/GITHUB_QGUO/Gold_Block_Data_Analysis/Data/Pilot/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a file with prolific id from the demographic file\n",
    "# for example pid_from_demographic('Cohort2_Pilot1_Demographic.csv','pid_Cohort2_Pilot.csv')\n",
    "# demo_file:demographic file \"xxx.csv\"\n",
    "# pid file \"xxx.csv\"\n",
    "def pid_from_demographic(demo_file,pid_file): \n",
    "    \n",
    "    path='C:/Users/guoqi/GITHUB_QGUO/Gold_Block_Data_Analysis/Data/Pilot/'\n",
    "    \n",
    "    demographic_data = pd.read_csv(os.path.join(path,demo_file)) \n",
    "    pid=demographic_data[demographic_data['Status'] == 'AWAITING REVIEW']\n",
    "    pid=pid['Participant id'].to_list()\n",
    "    # print(pid)\n",
    "    with open(os.path.join(path,pid_file), 'w',newline='') as csvfile:\n",
    "        # print(os.path.join(path,pid_file))\n",
    "        # print(csvfile)\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerows([pid])\n",
    "    return pid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculates sequence of comparisons, whether they swap and number of least necessary comparisons for an array with a certain order (for example: 6 4 3 1 5 2)\n",
    "#_f means forward and _b means backward\n",
    "def imit_seq(array):\n",
    "    aa=copy.copy(array)\n",
    "    comp_seq=[]\n",
    "    swap_or_not=[]\n",
    "    ii_f=0\n",
    "    nn=0\n",
    "    while nn<30:\n",
    "        \n",
    "        if aa[ii_f]<aa[ii_f+1]: #correct ofer and keep going forward\n",
    "            comp_seq.append([ii_f,ii_f+1])\n",
    "            swap_or_not.append(0)\n",
    "            nn+=1\n",
    "            ii_f+=1\n",
    "        else: #switch when going forward\n",
    "            comp_seq.append([ii_f,ii_f+1])\n",
    "            aa[ii_f],aa[ii_f+1]=aa[ii_f+1],aa[ii_f]\n",
    "            swap_or_not.append(1)\n",
    "            nn+=1\n",
    "\n",
    "            ii_b=ii_f\n",
    "            ii_f+=1\n",
    "\n",
    "            while nn<30:\n",
    "                if ii_b==0: #back to position zero\n",
    "                    break\n",
    "                if aa[ii_b-1]>aa[ii_b]: #switch and keep going back\n",
    "                    comp_seq.append([ii_b-1,ii_b])\n",
    "                    swap_or_not.append(1)\n",
    "                    aa[ii_b-1],aa[ii_b]=aa[ii_b],aa[ii_b-1]\n",
    "                    nn+=1\n",
    "                    ii_b-=1\n",
    "                if aa[ii_b-1]<aa[ii_b]: #stop going back\n",
    "                    if ii_b==0:\n",
    "                        break\n",
    "                    else:\n",
    "                        comp_seq.append([ii_b-1,ii_b])\n",
    "                        swap_or_not.append(0)\n",
    "                        nn+=1\n",
    "                        break\n",
    "        if (aa==np.array(range(1, len(array)+1, 1))).all():\n",
    "            if np.array([len(array)-2,len(array)-1]) in np.array(comp_seq):\n",
    "                break\n",
    "    return array,nn,comp_seq,swap_or_not\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# #verify n_nece_compare\n",
    "# arr_test=np.array([6,4,3,1,5,2]) #13\n",
    "# arr_test=np.array([1, 2, 3, 4, 8, 7, 6, 5])\n",
    "# # arr_test=np.array([2,1,4,3,6,5]) #7\n",
    "# # arr_test=np.array([4,6,3,2,5,1]) #13\n",
    "\n",
    "# print(imit_seq(arr_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a file with prolific id from the demogrphic file\n",
    "# demographic_data = pd.read_csv(\"C:/Users/guoqi/GITHUB_QGUO/Gold_Block_Data_Analysis/Data/Pilot/Cohort1_30Participants_Demographic.csv\") \n",
    "# # pid_data=demographic_data['Participant id']['Status'=='AWAITING REVIEW']\n",
    "# pid_data=demographic_data[demographic_data['Status'] == 'AWAITING REVIEW']\n",
    "# pid_data=pid_data['Participant id'].to_list()\n",
    "# # print(pid_data)\n",
    "# with open('C:/Users/guoqi/GITHUB_QGUO/Gold_Block_Data_Analysis/Data/Pilot/pid_Cohort1.csv', 'w') as csvfile:\n",
    "#     writer = csv.writer(csvfile)\n",
    "#     writer.writerows([pid_data])\n",
    "\n",
    "pid_data=pid_from_demographic('Cohort1_30Participants_Demographic.csv','pid_Cohort1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['6793751badf02fd55a1f0fb9', '66a0172986186ec228714d51', '66986c9ad97d2e5ff07329c1', '65610d3b7a06953204bbbb62', '677527596d51edae18442b1e', '6595ddebdbc6d36b1ef5462a', '6774ed8fea9a49a640664efb', '679359525d6dac68ab9d189f', '576704bffdff7a0001c12890', '6629517257384969d8995d78', '5a8cba1a8fe2dc00010643f0', '674934b4b6bd253249a72d63', '65bfa2967c731d263eb29732', '678d97abed191932719e540e', '678f1df528b89f7aa06b930e', '5e8f53644b34ff22d9b3a1c5', '655e3d32d5562c5520717cfc', '6747cb2578e508f43be65a76', '65e0fc6b883b6a493d50e0a5', '6733ba14d32d1b6b8d4b11d8', '671440da17d283b1ef1035be', '6712e63698e4785e4b2cf0a9', '6712fc1608041fe311ca2221', '63316daa57747115376760da', '63d87d4ba0b86684507f201d', '614e6f4f00a9e94b123316d3', '66e0ff9d08256be084cd8c81', '6427402d1463cb72eca94b3e', '5c6a36214fbf270001311702', '5f4eb642ce413e0ecc88e227']\n",
      "[30, 31, 32, 35, 36, 37, 42, 43, 44, 51, 52, 54, 55, 56, 57, 59, 60, 62, 63, 64, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76]\n",
      "['0fb9', '4d51', '29c1', 'bb62', '2b1e', '462a', '4efb', '2890', '189f', '5d78', '43f0', '9732', '540e', '930e', '5a76', '7cfc', 'a1c5', '2d63', '60da', '201d', '16d3', 'e0a5', '11d8', '35be', 'f0a9', '2221', '4b3e', '8c81', '1702', 'e227']\n"
     ]
    }
   ],
   "source": [
    "# Find Cognition.run datafiles corresponding to prolific ID\n",
    "cohort1_pid=[str(ii) for ii in pid_data]\n",
    "print(cohort1_pid)\n",
    "# cohort1_pid=[\"6793751badf02fd55a1f0fb9\",\"66a0172986186ec228714d51\",\"66986c9ad97d2e5ff07329c1\",\"65610d3b7a06953204bbbb62\",\"677527596d51edae18442b1e\",\"6595ddebdbc6d36b1ef5462a\",\"6774ed8fea9a49a640664efb\",\"576704bffdff7a0001c12890\",\"679359525d6dac68ab9d189f\",\"6629517257384969d8995d78\",\"5a8cba1a8fe2dc00010643f0\",\"65bfa2967c731d263eb29732\",\"678d97abed191932719e540e\",\"678f1df528b89f7aa06b930e\",\"655e3d32d5562c5520717cfc\",\"6747cb2578e508f43be65a76\",\"6733ba14d32d1b6b8d4b11d8\",\"65e0fc6b883b6a493d50e0a5\",\"671440da17d283b1ef1035be\"]\n",
    "path_cohort1='C:/Users/guoqi/GITHUB_QGUO/Gold_Block_Data_Analysis/Data/Pilot/Cohort1_30Participants_Jan31/'\n",
    "csv_files = glob.glob(os.path.join(path_cohort1, '*.csv')) \n",
    "# print(csv_files)\n",
    "run_id_cohort1=[]\n",
    "p_id_cohort1=[]\n",
    "for csv in csv_files:\n",
    "    data = pd.read_csv(csv) \n",
    "    # print(data['run_id'][0])\n",
    "    if 'PROLIFIC_PID'not in data:\n",
    "        # print(\"none\")\n",
    "        continue\n",
    "    elif 'phase' not in data:\n",
    "        # print(\"none\")\n",
    "        continue\n",
    "    else:\n",
    "        data_useful=data[[ 'run_id','PROLIFIC_PID']]\n",
    "        pid=data_useful['PROLIFIC_PID'][0]\n",
    "        pid_4=pid[-4:] #last four digit of prolific id\n",
    "    # print(data_useful['PROLIFIC_PID'])\n",
    "        if pid in cohort1_pid:\n",
    "            run_id_cohort1.append(data_useful['run_id'][0])\n",
    "            p_id_cohort1.append(pid_4)\n",
    "print(run_id_cohort1)\n",
    "print(p_id_cohort1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[30, 0.33230063123235054], [31, 0.11633625514467787], [32, 0.17036049915066243], [35, 0.7257363178538635], [36, 0.06712284154466518], [37, 0.8570336566096233], [42, 0.08178755047774773], [43, 0.1309056974648293], [44, 0.9121280162145547], [51, 0.019457573090183138], [52, 0.3992947581140515], [54, 0.1617997893590027], [55, 1.0], [56, 0.9185890631804092], [57, 0.03852352010597225], [59, 0.005896058860678609], [60, 0.8185758571002164], [62, 0.23498455108164368], [63, 1.0], [64, 0.09645548094357688], [66, 0.8382364014856705], [67, 0.04500205120521715], [68, 0.05165993983169494], [69, 0.017419206004111943], [70, 0.01869198488671813], [71, 0.02196334794343035], [72, 1.0], [73, 0.0745801926771332], [75, 0.5218582736011069], [76, 0.2658326083129622]]\n",
      "[[55, 1.0], [63, 1.0], [72, 1.0], [56, 0.9185890631804092], [44, 0.9121280162145547], [37, 0.8570336566096233], [66, 0.8382364014856705], [60, 0.8185758571002164], [35, 0.7257363178538635], [75, 0.5218582736011069], [52, 0.3992947581140515], [30, 0.33230063123235054], [76, 0.2658326083129622], [62, 0.23498455108164368], [32, 0.17036049915066243], [54, 0.1617997893590027], [43, 0.1309056974648293], [31, 0.11633625514467787], [64, 0.09645548094357688], [42, 0.08178755047774773], [73, 0.0745801926771332], [36, 0.06712284154466518], [68, 0.05165993983169494], [67, 0.04500205120521715], [57, 0.03852352010597225], [71, 0.02196334794343035], [51, 0.019457573090183138], [70, 0.01869198488671813], [69, 0.017419206004111943], [59, 0.005896058860678609]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate score of how well participants learn gnome sort\n",
    "p_mean_cohort=[]\n",
    "p_mean_list=[]\n",
    "p_half_mean_list=[]\n",
    "for pp in run_id_cohort1:\n",
    "    data=pd.read_csv(path_cohort1+str(pp)+'.csv')\n",
    "    data_useful=data[['trial_type','time_elapsed', 'run_id','PROLIFIC_PID','STUDY_ID','stimulus','response','phase','question_order']]\n",
    "        \n",
    "    p_gnome_all=[]\n",
    "    for ii in range(0,10):\n",
    "        indices_test=data_useful[data_useful['phase'] == \"Test \"+str(ii)].index.to_numpy()\n",
    "        fin_order_test=data_useful['phase'][max(indices_test)+1]\n",
    "        fin_order_test=fin_order_test[13:].split(\",\")\n",
    "        fin_order_test=[int(x) for x in fin_order_test]==[1,2,3,4,5] or [int(x) for x in fin_order_test]==[1,2,3,4,5,6,7,8]\n",
    "    \n",
    "        ini_order_test=data_useful['phase'][min(indices_test)-1]\n",
    "        ini_order_test=ini_order_test[15:].split(\",\")\n",
    "        ini_order_test=[int(x)+1 for x in ini_order_test]\n",
    "    \n",
    "        comp_test = [data['response'][i] for i in indices_test]\n",
    "        comp_test=[int(x) for x in comp_test]\n",
    "        comp_test=comp_test[:-1]\n",
    "        if len(comp_test)%2==1:\n",
    "            comp_test=comp_test[:-1]\n",
    "        n_comp_ptcp=int(len(comp_test)/2) #number of comparison made by participants\n",
    "        comp_test=np.reshape(comp_test, (n_comp_ptcp, 2)).tolist()\n",
    "        # print(comp_test)\n",
    "        for row in comp_test:\n",
    "            if row[0]==row[1]:\n",
    "                comp_test.remove(row)\n",
    "        for row in comp_test:\n",
    "            if row[0]>row[1]:\n",
    "                cache=row[0]\n",
    "                row[0]=row[1]\n",
    "                row[1]=cache\n",
    "        # print(fin_order_test)\n",
    "        # print(comp_test)\n",
    "    \n",
    "        \n",
    "        windows_test={}\n",
    "        for jj in range(len(comp_test),1,-1):\n",
    "            for kk in range(0,len(comp_test)-jj+1):\n",
    "                if jj not in windows_test.keys():\n",
    "                    windows_test[jj]=[comp_test[kk:(kk+jj)]]\n",
    "                else:\n",
    "                    windows_test[jj].append(comp_test[kk:(kk+jj)])\n",
    "        # print(windows_test)\n",
    "        \n",
    "    \n",
    "        array_cache,nn_cache,comp_seq_true,swap_or_not_cache=imit_seq(np.array(ini_order_test))\n",
    "        # print(comp_seq_true)\n",
    "        \n",
    "        windows_true={}\n",
    "        for jj in range(len(comp_seq_true),1,-1):\n",
    "            for kk in range(0,len(comp_seq_true)-jj+1):\n",
    "                if jj not in windows_true.keys():\n",
    "                    windows_true[jj]=[comp_seq_true[kk:(kk+jj)]]\n",
    "                else:\n",
    "                    windows_true[jj].append(comp_seq_true[kk:(kk+jj)])\n",
    "        # print(windows_true)\n",
    "    \n",
    "        common_size=min(len(comp_seq_true),len(comp_test))\n",
    "        n_comp_true=len(comp_seq_true) #number of comparison for correct gnome\n",
    "        sim={}\n",
    "        for mm in range(2,n_comp_true+1):\n",
    "            sim[mm]=0\n",
    "            if mm<=common_size:\n",
    "                win_test=windows_test[mm]\n",
    "                win_true=windows_true[mm]\n",
    "                for comp_test in win_test:\n",
    "                    if comp_test in win_true:\n",
    "                        sim[mm]+=1\n",
    "            else:\n",
    "                sim[mm]=0\n",
    "        # print(sim)\n",
    "    \n",
    "        sum_test=0\n",
    "        sum_true=0\n",
    "        for key in sim.keys():\n",
    "            # sum_true+=key*(common_size-key+1)*(1/2)**(common_size-key)\n",
    "            sum_true+=key\n",
    "            if sim[key]>0:\n",
    "                # sum_test=key\n",
    "                # sum_test+=key*sim[key]*(1/2)**(common_size-key)\n",
    "                sum_test+=key*sim[key]/len(windows_true[key])\n",
    "        if sum_test>sum_true:\n",
    "            sum_test=sum_true\n",
    "        # print(sum_test/sum_true)       \n",
    "    \n",
    "    \n",
    "        # for ii in range(len(comp_seq_true),1,-1):\n",
    "        #     sum_true+=ii*(common_size-ii+1)*(1/2)**(common_size-ii)\n",
    "    \n",
    "        p_gnome=sum_test/sum_true\n",
    "        p_gnome_all.append(p_gnome)\n",
    "    # p_gnome_all=np.array(p_gnome_all)\n",
    "    # print(p_gnome_all)\n",
    "    p_half_criteria=np.quantile(p_gnome_all, 0.5)\n",
    "    \n",
    "    p_half=[p for p in p_gnome_all if p>=p_half_criteria]\n",
    "    p_half_mean=np.average(p_half)\n",
    "    p_half_mean_list.append(p_half_mean)\n",
    "\n",
    "\n",
    "    p_mean=np.average(p_gnome_all)\n",
    "    p_mean_list.append(p_mean)\n",
    "    p_mean_cohort.append([pp,p_mean])\n",
    "    \n",
    "    # print(p_mean)\n",
    "    # p_gnome_all[p_gnome_all>=p_half]\n",
    "        # print(sum_true,sum_test)\n",
    "\n",
    "plt.hist(p_half_mean_list, bins=20, color='skyblue', edgecolor='black')\n",
    "print(p_mean_cohort)           \n",
    "p_cohort_sorted=sorted(p_mean_cohort, key=lambda x: x[1],reverse=True)\n",
    "print(p_cohort_sorted)\n",
    "\n",
    "\n",
    "\n",
    "# index_crclm=data_useful[data_useful['trial_type'] == \"survey-multi-choice\"].index.to_numpy()\n",
    "\n",
    "# crclm=data_useful['response'][index_crclm]\n",
    "# index_ling=data_useful[data_useful['trial_type'] == \"survey-text\"].index.to_numpy()\n",
    "# ling=data_useful['response'][index_ling]\n",
    "# # crclm=crclm.split(\",\")\n",
    "# print(crclm)\n",
    "# print(ling)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii=0\n",
    "# ling_all=[]\n",
    "ling_all_cohort1=[]\n",
    "run_id_sorted=[]\n",
    "for [run_id,score] in p_cohort_sorted:\n",
    "    \n",
    "    data=pd.read_csv(path_cohort1+str(run_id)+'.csv')\n",
    "    data_useful=data[['trial_type','time_elapsed', 'run_id','PROLIFIC_PID','STUDY_ID','stimulus','response','phase','question_order']]\n",
    "    index_ling=data_useful[data_useful['trial_type'] == \"survey-text\"].index.to_numpy()\n",
    "    ling=str(list(data_useful['response'][index_ling]))\n",
    "    ling=ling[9:-4]\n",
    "    ling=ling.replace(\"\\\\\\\\n\", \"<br>\") \n",
    "    ling=ling.replace(\"\\\\\", \"\")\n",
    "    ling_all_cohort1.append(ling)\n",
    "    run_id_sorted.append(run_id)\n",
    "\n",
    "    if ii==0:\n",
    "        initial_data = {'run_id': [run_id], \n",
    "                'Notes': [ling]}\n",
    "        ling_id_df = pd.DataFrame(initial_data, columns = ['run_id', 'Notes'])\n",
    "    else:\n",
    "        ling_id_df.loc[len(ling_id_df)] = [run_id, ling]\n",
    "\n",
    "    ii+=1\n",
    "    # if ii>15:\n",
    "    #     break\n",
    "\n",
    "\n",
    "# print(ling_id_df)\n",
    "ling_id_df.to_csv(os.path.join(path_up,'Note_cohort1.csv'))\n",
    "\n",
    "# # import csv\n",
    "# with open(os.path.join(path_up,'Note_cohort1.csv'), 'w') as csvfile:\n",
    "#         writer = csv.writer(csvfile)\n",
    "#         writer.writerows(ling_id_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Check if it is moving left to right. They check blocks next to each other starting from the very left. If they don't swap go to the 2nd and 3rd blocks. If they do swap then check if there are any more swaps with previous blocks. Then go back to where you were.\", \"Step 1: Designate the leftmost object as Object A.<br><br>Step 2: Check if swapping Object A with its right neighbor is valid (based on a predefined rule, such as its weight).<br><br>If invalid, designate the right neighbor as the new Object A and repeat Step 2.<br><br>If valid, swap their positions, designate the swapped neighbor as Object B, note Object Aâ€™s position, and proceed to Step 3.<br><br>Step 3: Propagate Object B to the left, following the same logic as Step 2 but with two changes:<br><br>The goal direction is now left.<br><br>If a swap fails, assume Object B is sorted and return to Step 2 and remember Object A's position.\", 'Start by comparing the first two blocks. Then progress by comparing the blocks in the 2nd and 3rd position, and then the 3rd and 4th, and so on.<br><br>Whenever a swap happens, keep note of the \"leading\" block that was placed ahead (to the right). If a swap does not happen, the block on the right that was compared becomes the new \"leading\" block. The block that was just swapped behind the \"leading\" block then needs to be compared to the block behind it. If a swap happens, again compare it to the block behind it. Repeat this until a swap does not happen or until it is placed in the first position. Then return to your \"leading\" block and compare it to the block ahead of it.', 'Continue to swap pieces until you have put them as far to the left as they will allow.', 'as you sort the gold blocks, compare them to the previous and next blocks to sort them.', \"Instead of using a compare the first block to the second block, then compare the first block to the third block, etc., the Omgne Sort is a more direct and less repetitive sorting system which doesn't repeat steps over and over. The Omgne Sort compares the first block to the second and then the second to the third. Only when there is an actual block swap do you then go backwards in your possible swapping of blocks, i.e. if the fourth and fifth blocks swap, then you go backwards trying to swap blocks until they don't swap anymore.\", 'Start left from right and if there is a change keep passing it to the left until it can not move anymore then move on to the next block ', 'compare each with precious block after each swap', \"Start with the first block and move it to the right as far as it will go.  Then check all the blocks that moved against each other, moving them as necessary.  When nothing can move to the left, you've done it correctly.\", 'go from left to right selecting 2 at a time.', 'Sort the heavy first by selecting and moving them the opposite way', \"Hi Students. look out for the number of swaps in a sequence. If you swap in a rightly arranged sequence of 5 8 times, that's very out of order.\", 'The Omgne Sort patterns makes it easy for better understanding and accurate results<br>It is such an easy pattern mostly.<br>Usually in a numerical order.', 'move the animals randomly until they dont switch positions', 'Hi There, the least number of swaps has the tendency for a correct order.']\n"
     ]
    }
   ],
   "source": [
    "#every other notes\n",
    "ling_id_df_half=ling_id_df.iloc[::2, :]\n",
    "ling_id_df_half=ling_id_df_half.groupby(ling_id_df_half.index // 2).first()\n",
    "ling_id_df_half_list=ling_id_df_half['Notes'].tolist()\n",
    "# ling_id_df_half.index/22\n",
    "print(ling_id_df_half_list)\n",
    "# ling_id_df_half"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analayzing experiments with note rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['663e3cee91031227e894384a', '659ac6d9e91b332d5e91216c', '60fe08ddc8e72aef56771482', '6442842843aab883445d6708', '667abe08bc794718ca0cf87b', '5f4d3cb5fdda0b2c403fb801', '6685bda9fe63421c0f632414', '661de1d2f9c50b06f796b9cc', '6413c7853eba2b2215197ff4', '62e057323b4ee04dd8f508f6', '5d9264f527fdac00158fd876', '67549868a9ea0e2c285a8f14', '677a8053e35cb9c094676a79', '627f448165ed9095fd43cfd1', '5a79f14a8fe2dc00010593eb', '670db0b5fbb9e80cbee561cc', '674d396ea5a143c1fe1ff5bc', '5d5580165514d80017cd1999', '6762c5c001ce66a8d666441a', '656fc7d36afa7a7199fe7c75', '67007d655b10fbe2d93c3508', '673a8d64bf587131fa065ec5', '664efd1322a0666254a51974', '666dd3d9e53e0ff59d7cc164', '671d44c91d7089c757cf3a7e', '67265982eb0c3fc495c6e33a', '64012a2623351894f2917605', '5aa806e7777df200016088c5', '6444b1e677ebe8b4e2c23abd']\n",
      "[11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 26, 28, 29, 30, 31, 32, 33, 36, 38, 40, 41, 42, 43, 44, 45, 46, 9]\n",
      "['216c', '1482', '6708', 'f87b', 'b801', '2414', 'b9cc', '7ff4', '08f6', 'd876', '6a79', '2414', '93eb', '61cc', 'cfd1', 'f5bc', '1999', '441a', '7c75', '3508', '5ec5', '1974', '3a7e', 'c164', 'e33a', '7605', '88c5', '3abd', '384a']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "pid_cohort2=pid_from_demographic('Cohort2_Demographic.csv','pid_Cohort2.csv')\n",
    "\n",
    "# Find Cognition.run datafiles corresponding to prolific ID\n",
    "cohort2_pid=[str(ii) for ii in pid_cohort2]\n",
    "print(cohort2_pid)\n",
    "path_cohort2='C:/Users/guoqi/GITHUB_QGUO/Gold_Block_Data_Analysis/Data/Pilot/Cohort2_30Participants/'\n",
    "csv_files = glob.glob(os.path.join(path_cohort2, '*.csv')) \n",
    "# print(csv_files)\n",
    "run_id_cohort=[]\n",
    "p_id_cohort=[]\n",
    "for csv in csv_files:\n",
    "    data = pd.read_csv(csv) \n",
    "    # print(data['phase'])\n",
    "    # print(data['run_id'][0])\n",
    "    if 'PROLIFIC_PID'not in data:\n",
    "        # print(\"none\")\n",
    "        continue\n",
    "    elif 'phase' not in data:\n",
    "        # print(\"none\")\n",
    "        continue\n",
    "    elif 'presented_choices' not in data:\n",
    "        continue\n",
    "    else:\n",
    "        data_useful=data[['run_id','PROLIFIC_PID']]\n",
    "        pid_cache=data_useful['PROLIFIC_PID'][0]\n",
    "        pid_4=pid_cache[-4:] #last four digit of prolific id\n",
    "    # print(data_useful['PROLIFIC_PID'])\n",
    "        # print(pid)\n",
    "        if pid_cache in cohort2_pid:\n",
    "            # print(\"yes\")\n",
    "            run_id_cohort.append(data_useful['run_id'][0])\n",
    "            p_id_cohort.append(pid_4)\n",
    "print(run_id_cohort)\n",
    "print(p_id_cohort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_id is 11\n",
      "run_id is 12\n",
      "run_id is 13\n",
      "run_id is 14\n",
      "run_id is 15\n",
      "run_id is 16\n",
      "run_id is 17\n",
      "run_id is 18\n",
      "run_id is 19\n",
      "run_id is 20\n",
      "run_id is 22\n",
      "run_id is 23\n",
      "run_id is 26\n",
      "run_id is 28\n",
      "run_id is 29\n",
      "run_id is 30\n",
      "run_id is 31\n",
      "run_id is 32\n",
      "run_id is 33\n",
      "run_id is 36\n",
      "run_id is 38\n",
      "run_id is 40\n",
      "run_id is 41\n",
      "run_id is 42\n",
      "run_id is 43\n",
      "Rating Skipped\n",
      "run_id is 44\n",
      "run_id is 45\n",
      "run_id is 46\n",
      "run_id is 9\n",
      "[[ 0.  4.  2.  1.  1.  4.  3.  6.  1.  0.  3.  1.  4.  0.  3.]\n",
      " [16.  0.  2.  5.  1.  2.  0.  2.  1.  1.  0.  2.  0.  3.  0.]\n",
      " [ 6.  5.  0.  2.  2.  1.  2.  1.  0.  2.  1.  3.  0.  0.  0.]\n",
      " [ 6.  1.  4.  0.  9.  3.  2.  2.  4.  0.  2.  0.  1.  2.  1.]\n",
      " [ 6.  1.  5.  2.  0.  6.  2.  1.  1.  4.  1.  1.  1.  4.  1.]\n",
      " [ 4.  1.  2.  0.  3.  0.  3.  0.  2.  1.  1.  3.  0.  1.  1.]\n",
      " [ 1.  0.  1.  3.  0.  1.  0.  2.  1.  2.  2.  1.  1.  2.  2.]\n",
      " [ 3.  1.  3.  4.  2.  2.  1.  0.  2.  3.  1.  2.  2.  2.  2.]\n",
      " [ 3.  2.  3.  0.  1.  1.  1.  0.  0.  1.  1.  0.  2.  0.  5.]\n",
      " [ 3.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.  0.  2.  0.  2.]\n",
      " [ 4.  1.  1.  0.  3.  0.  1.  1.  2.  1.  0.  2.  2.  2.  0.]\n",
      " [ 2.  0.  1.  1.  0.  0.  1.  1.  2.  0.  0.  0.  0.  0.  0.]\n",
      " [ 5.  1.  2.  2.  1.  0.  1.  1.  0.  2.  2.  0.  0.  0.  3.]\n",
      " [ 1.  1.  1.  1.  0.  1.  0.  1.  1.  0.  3.  0.  3.  0.  0.]\n",
      " [ 2.  0.  2.  1.  3.  0.  1.  2.  1.  2.  2.  0.  2.  1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "#Preprocess for Bradley-Terry Model\n",
    "\n",
    "matrix_rating_total=np.zeros((15,15))\n",
    "for run_id in run_id_cohort:\n",
    "    matrix_rating=np.zeros((15,15))\n",
    "    print(\"run_id is\",run_id)\n",
    "    # data = pd.read_csv(csv) \n",
    "    data=pd.read_csv(path_cohort2+str(run_id)+'.csv')\n",
    "    data_useful=data[['trial_type','time_elapsed', 'run_id','PROLIFIC_PID','STUDY_ID','stimulus','response','phase','presented_choices']]\n",
    "    # print(data_useful)\n",
    "\n",
    "    \n",
    "\n",
    "    for ii in range(0,14):\n",
    "        if ii!=5 and ii!=9:\n",
    "            indices_rating=data_useful[data_useful['phase'] == \"Note Comparison\"].index.to_numpy()\n",
    "            # print(indices_rating)\n",
    "            index_choices=min(indices_rating)+(ii*2)\n",
    "            index_betterone=index_choices+1\n",
    "            # print(index_choices)\n",
    "            # print(index_betterone)\n",
    "            choices=data_useful['presented_choices'][min(indices_rating)+(ii*2)].split('\",\"')\n",
    "            # print(len(choices))\n",
    "            choices = [s.replace('[\"', '') for s in choices]  \n",
    "            choices = [s.replace('\"]', '') for s in choices]  \n",
    "            choices = [s.replace('\\\\', '') for s in choices]  \n",
    "\n",
    "            indices_two_notes=[]\n",
    "            for choice in choices:\n",
    "                # print(choice)\n",
    "                index_note=ling_id_df_half_list.index(choice)\n",
    "                # print(index_note)\n",
    "                # ling_id_df_half.tolist()\n",
    "                indices_two_notes.append(index_note)\n",
    "                run_id_note=run_id_sorted[index_note]\n",
    "                # print(index_note)\n",
    "                # print(\"length\")\n",
    "                # print(min(indices_rating)+(ii*2)+1)\n",
    "                # print(len(data_useful))\n",
    "            if (min(indices_rating)+(ii*2)+2)>len(data_useful):\n",
    "                print('Rating Skipped')\n",
    "            else:\n",
    "                # print(\"indices\",indices_two_notes)\n",
    "                better_one=data_useful['response'][min(indices_rating)+(ii*2)+1]\n",
    "                a=indices_two_notes[0]\n",
    "                b=indices_two_notes[1]\n",
    "                if better_one==0:\n",
    "                    matrix_rating[a][b]+=1\n",
    "                else:\n",
    "                    matrix_rating[b][a]+=1\n",
    "    matrix_rating_total=matrix_rating_total+matrix_rating\n",
    "print(matrix_rating_total)\n",
    "# np.matrix(matrix_rating).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.63983316 1.04331568 0.65981147 2.27037535]\n"
     ]
    }
   ],
   "source": [
    "#Validating Bradley-Terry model based on worked example on wikipedia\n",
    "matrix_example=[[0,2,0,1],[3,0,5,0],[0,3,0,1],[4,0,3,0]]\n",
    "# matrix_win_lose_df=pd.DataFrame(matrix_win_lose,columns=['A','B','C','D'],index=['A','B','C','D'])\n",
    "matrix_example_df=pd.DataFrame(matrix_example)\n",
    "\n",
    "def BT(matrix_win_lose):\n",
    "    p_list_converge=[]\n",
    "    p_list=np.ones(len(matrix_win_lose))\n",
    "    for jj in range(100):\n",
    "        multi_all=1\n",
    "        for ii in range(len(p_list)):\n",
    "            wij=matrix_win_lose.iloc[ii]\n",
    "            wji=matrix_win_lose[ii]\n",
    "            pij_nom=p_list/(p_list[ii]+p_list)\n",
    "            pij_den=1/(p_list[ii]+p_list)\n",
    "            p_list[ii]=sum(wij*pij_nom)/sum(wji*pij_den)\n",
    "            multi_all*=p_list[ii]\n",
    "        geo_mean=multi_all**(1/len(p_list))\n",
    "        p_list=p_list/geo_mean\n",
    "        p_list_converge.append(p_list)\n",
    "        if jj>0 and abs(sum(p_list_converge[jj])-sum(p_list_converge[jj-1]))<0.00001:\n",
    "            break\n",
    "    return p_list\n",
    "# print(p_list_converge)\n",
    "print(BT(matrix_example_df))\n",
    "# print(geo_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6214567  1.74906992 0.92456393 1.75471508 1.43005868 1.07654789\n",
      " 1.0520941  1.44617014 1.06302724 0.54954727 0.9392574  0.56717607\n",
      " 0.91677382 0.91591667 0.92641819]\n"
     ]
    }
   ],
   "source": [
    "print(BT(pd.DataFrame(matrix_rating_total)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
