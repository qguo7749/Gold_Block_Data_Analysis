{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Things to get from data\n",
    "1. time tkane for introduction trial ([4,2,3,5,1])\n",
    "2. time taken for each imitation trial\n",
    "3. initial states, sequence of comparison, final state for each test trial\n",
    "4. choices for demo trials\n",
    "5. initial states, sequence of comparison, final state for each demo trial\n",
    "6. description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import glob \n",
    "import os \n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculates sequence of comparisons, whether they swap and number of least necessary comparisons for an array with a certain order (for example: 6 4 3 1 5 2)\n",
    "#_f means forward and _b means backward\n",
    "def imit_seq(array):\n",
    "    aa=copy.copy(array)\n",
    "    comp_seq=[]\n",
    "    swap_or_not=[]\n",
    "    ii_f=0\n",
    "    nn=0\n",
    "    while nn<30:\n",
    "        \n",
    "        if aa[ii_f]<aa[ii_f+1]: #correct ofer and keep going forward\n",
    "            comp_seq.append([ii_f,ii_f+1])\n",
    "            swap_or_not.append(0)\n",
    "            nn+=1\n",
    "            ii_f+=1\n",
    "        else: #switch when going forward\n",
    "            comp_seq.append([ii_f,ii_f+1])\n",
    "            aa[ii_f],aa[ii_f+1]=aa[ii_f+1],aa[ii_f]\n",
    "            swap_or_not.append(1)\n",
    "            nn+=1\n",
    "\n",
    "            ii_b=ii_f\n",
    "            ii_f+=1\n",
    "\n",
    "            while nn<30:\n",
    "                if ii_b==0: #back to position zero\n",
    "                    break\n",
    "                if aa[ii_b-1]>aa[ii_b]: #switch and keep going back\n",
    "                    comp_seq.append([ii_b-1,ii_b])\n",
    "                    swap_or_not.append(1)\n",
    "                    aa[ii_b-1],aa[ii_b]=aa[ii_b],aa[ii_b-1]\n",
    "                    nn+=1\n",
    "                    ii_b-=1\n",
    "                if aa[ii_b-1]<aa[ii_b]: #stop going back\n",
    "                    if ii_b==0:\n",
    "                        break\n",
    "                    else:\n",
    "                        comp_seq.append([ii_b-1,ii_b])\n",
    "                        swap_or_not.append(0)\n",
    "                        nn+=1\n",
    "                        break\n",
    "        if (aa==np.array(range(1, len(array)+1, 1))).all():\n",
    "            if np.array([len(array)-2,len(array)-1]) in np.array(comp_seq):\n",
    "                break\n",
    "    return array,nn,comp_seq,swap_or_not\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# #verify n_nece_compare\n",
    "# arr_test=np.array([6,4,3,1,5,2]) #13\n",
    "# arr_test=np.array([1, 2, 3, 4, 8, 7, 6, 5])\n",
    "# # arr_test=np.array([2,1,4,3,6,5]) #7\n",
    "# # arr_test=np.array([4,6,3,2,5,1]) #13\n",
    "\n",
    "# print(imit_seq(arr_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_up='C:/Users/guoqi/GITHUB_QGUO/Gold_Block_Data_Analysis/Data/Pilot/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a file with prolific id from the demographic file\n",
    "# for example pid_from_demographic('Cohort2_Pilot1_Demographic.csv','pid_Cohort2_Pilot.csv')\n",
    "# demo_file:demographic file \"xxx.csv\"\n",
    "# pid file \"xxx.csv\"\n",
    "def pid_from_demographic(demo_file,pid_file): \n",
    "    \n",
    "    path='C:/Users/guoqi/GITHUB_QGUO/Gold_Block_Data_Analysis/Data/Pilot/'\n",
    "    \n",
    "    demographic_data = pd.read_csv(os.path.join(path,demo_file)) \n",
    "    pid=demographic_data[demographic_data['Status'] == 'AWAITING REVIEW']\n",
    "    pid=pid['Participant id'].to_list()\n",
    "    # print(pid)\n",
    "    with open(os.path.join(path,pid_file), 'w',newline='') as csvfile:\n",
    "        # print(os.path.join(path,pid_file))\n",
    "        # print(csvfile)\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerows([pid])\n",
    "    return pid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pair prolific ID with run_id to find Cognition.run datafiles corresponding to prolific ID\n",
    "def ids(pid_list,data_path,col_check):\n",
    "    #pid_list is all pid from demographic file with \"awaiting review\"\n",
    "    #dat_path is the path for data files\n",
    "    #col_check is the columns to be checked ('PROLIFIC ID' for example)\n",
    "    \n",
    "    pid_whole_cohort=[str(ii) for ii in pid_list]\n",
    "    # print(pid_whole_cohort)\n",
    "    \n",
    "    csv_files = glob.glob(os.path.join(data_path, '*.csv')) \n",
    "    run_id_cohort=[]\n",
    "    p_id_cohort=[]\n",
    "    p_id_last4=[]\n",
    "    for csv in csv_files:\n",
    "        data = pd.read_csv(csv) \n",
    "        if not all(col in data.columns for col in col_check):\n",
    "            continue\n",
    "        else:\n",
    "            data_useful=data[['run_id','PROLIFIC_PID']]\n",
    "            pid_cache=data_useful['PROLIFIC_PID'][0]\n",
    "            # pid_4=pid_cache[-4:] #last four digit of prolific id\n",
    "            if pid_cache in pid_whole_cohort:\n",
    "                run_id_cohort.append(data_useful['run_id'][0])\n",
    "                p_id_cohort.append(pid_cache)\n",
    "                p_id_last4.append(pid_cache[-4:])\n",
    "    ids_df = pd.DataFrame(\n",
    "    {'run_id': run_id_cohort,\n",
    "     'pid': p_id_cohort,\n",
    "     'pid_last4': p_id_last4\n",
    "    })\n",
    "    return ids_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8335518648018647\n"
     ]
    }
   ],
   "source": [
    "def score(run_id,n_test,data_path,quantile):\n",
    "        data=pd.read_csv(data_path+str(run_id)+'.csv')\n",
    "        data_useful=data[['trial_type','time_elapsed', 'run_id','PROLIFIC_PID','STUDY_ID','stimulus','response','phase','question_order']]\n",
    "            \n",
    "        p_gnome_all=[]\n",
    "        for ii in range(0,n_test):\n",
    "            indices_test=data_useful[data_useful['phase'] == \"Test \"+str(ii)].index.to_numpy()\n",
    "            # print(indices_test)\n",
    "\n",
    "            # get final order in test trials of participants\n",
    "            fin_order_test=data_useful['phase'][max(indices_test)+1]\n",
    "            fin_order_test=fin_order_test[13:].split(\",\")\n",
    "            fin_order_test=[int(x) for x in fin_order_test]==[1,2,3,4,5] or [int(x) for x in fin_order_test]==[1,2,3,4,5,6,7,8] #true for correct sorting\n",
    "\n",
    "        \n",
    "            # get initial order in test trials\n",
    "            ini_order_test=data_useful['phase'][min(indices_test)-1]\n",
    "            ini_order_test=ini_order_test[15:].split(\",\")\n",
    "            ini_order_test=[int(x)+1 for x in ini_order_test]\n",
    "            \n",
    "        \n",
    "            comp_test = [data['response'][i] for i in indices_test]\n",
    "            comp_test=[int(x) for x in comp_test]\n",
    "            comp_test=comp_test[:-1]\n",
    "            if len(comp_test)%2==1:\n",
    "                comp_test=comp_test[:-1]\n",
    "            n_comp_ptcp=int(len(comp_test)/2) #number of comparison made by participants\n",
    "            comp_test=np.reshape(comp_test, (n_comp_ptcp, 2)).tolist()\n",
    "            \n",
    "\n",
    "            for row in comp_test:\n",
    "                if row[0]==row[1]:\n",
    "                    comp_test.remove(row)\n",
    "            for row in comp_test:\n",
    "                if row[0]>row[1]:\n",
    "                    cache=row[0]\n",
    "                    row[0]=row[1]\n",
    "                    row[1]=cache\n",
    "            # print(comp_test)\n",
    "\n",
    "        \n",
    "            #Sliding windows\n",
    "            windows_test={}\n",
    "            for jj in range(len(comp_test),1,-1):\n",
    "                for kk in range(0,len(comp_test)-jj+1):\n",
    "                    if jj not in windows_test.keys():\n",
    "                        windows_test[jj]=[comp_test[kk:(kk+jj)]]\n",
    "                    else:\n",
    "                        windows_test[jj].append(comp_test[kk:(kk+jj)])\n",
    "            \n",
    "            array_cache,nn_cache,comp_seq_true,swap_or_not_cache=imit_seq(np.array(ini_order_test))\n",
    "            # print(comp_seq_true)\n",
    "            \n",
    "            windows_true={}\n",
    "            for jj in range(len(comp_seq_true),1,-1):\n",
    "                for kk in range(0,len(comp_seq_true)-jj+1):\n",
    "                    if jj not in windows_true.keys():\n",
    "                        windows_true[jj]=[comp_seq_true[kk:(kk+jj)]]\n",
    "                    else:\n",
    "                        windows_true[jj].append(comp_seq_true[kk:(kk+jj)])\n",
    "        \n",
    "            common_size=min(len(comp_seq_true),len(comp_test))\n",
    "            n_comp_true=len(comp_seq_true) #number of comparison for correct gnome\n",
    "            sim={}\n",
    "            for mm in range(2,n_comp_true+1):\n",
    "                sim[mm]=0\n",
    "                if mm<=common_size:\n",
    "                    win_test=windows_test[mm]\n",
    "                    win_true=windows_true[mm]\n",
    "                    for comp_test in win_test:\n",
    "                        if comp_test in win_true:\n",
    "                            sim[mm]+=1\n",
    "                else:\n",
    "                    sim[mm]=0\n",
    "            # print(sim)\n",
    "\n",
    "        \n",
    "            sum_test=0\n",
    "            sum_true=0\n",
    "            for key in sim.keys():\n",
    "                sum_true+=key*(len(comp_seq_true)-key)\n",
    "                # sum_true+=key\n",
    "                if sim[key]>0:\n",
    "                    # sum_test+=key*sim[key]/len(windows_true[key])\n",
    "                    sum_test+=key*sim[key]\n",
    "            if sum_test>sum_true:\n",
    "                sum_test=sum_true    \n",
    "            # print(sum_test)\n",
    "            # print(sum_true)\n",
    "\n",
    "            p_gnome=sum_test/sum_true\n",
    "            p_gnome_all.append(p_gnome)\n",
    "\n",
    "        p_quantile_criteria=np.quantile(p_gnome_all, quantile)\n",
    "        \n",
    "        p_quantile=[p for p in p_gnome_all if p>=p_quantile_criteria]\n",
    "        p_quantile_mean=np.average(p_quantile)\n",
    "        # print('checkmark',p_quantile_mean)\n",
    "\n",
    "        return p_quantile_mean\n",
    "\n",
    "n_test=10\n",
    "quantile=0.5\n",
    "run_id=52\n",
    "path_cohort1='C:/Users/guoqi/GITHUB_QGUO/Gold_Block_Data_Analysis/Data/Pilot/Cohort1_30Participants_Jan31/'\n",
    "aa=score(run_id,n_test,path_cohort1,quantile)\n",
    "print(aa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cohort 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid_cohort1_total=pid_from_demographic('Cohort1_30Participants_Demographic.csv','pid_Cohort1.csv')\n",
    "path_cohort1='C:/Users/guoqi/GITHUB_QGUO/Gold_Block_Data_Analysis/Data/Pilot/Cohort1_30Participants_Jan31/'\n",
    "ids_cohort1=ids(pid_cohort1_total,path_cohort1,['PROLIFIC_PID','phase'])\n",
    "run_id_cohort1=ids_cohort1['run_id']\n",
    "run_id_cohort1_list=run_id_cohort1.values.tolist()\n",
    "n_test=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    run_id  performance  performance_best5   Curriculum_n_item  \\\n",
      "12    55.0     1.000000           1.000000  [5, 8, 5, 8, 5, 8]   \n",
      "26    63.0     1.000000           1.000000  [5, 8, 5, 5, 8, 8]   \n",
      "18    72.0     1.000000           1.000000  [5, 5, 5, 5, 8, 8]   \n",
      "13    56.0     0.942081           1.000000  [5, 8, 5, 8, 5, 8]   \n",
      "8     44.0     0.928959           1.000000  [5, 5, 5, 8, 8, 5]   \n",
      "5     37.0     0.905773           1.000000  [5, 8, 5, 5, 8, 8]   \n",
      "20    66.0     0.888285           1.000000  [5, 8, 5, 5, 8, 8]   \n",
      "3     35.0     0.859265           1.000000  [5, 8, 5, 5, 8, 8]   \n",
      "16    60.0     0.847537           1.000000  [5, 5, 5, 5, 5, 5]   \n",
      "28    75.0     0.622118           1.000000  [5, 8, 5, 8, 5, 8]   \n",
      "10    52.0     0.533691           0.833552  [5, 5, 5, 8, 8, 8]   \n",
      "0     30.0     0.503541           0.780500  [5, 8, 8, 8, 8, 8]   \n",
      "29    76.0     0.457299           0.708104  [5, 8, 5, 8, 5, 5]   \n",
      "17    62.0     0.429623           0.740314  [5, 8, 5, 5, 8, 8]   \n",
      "7     43.0     0.303902           0.503000  [5, 5, 5, 8, 8, 8]   \n",
      "1     31.0     0.296726           0.471601  [5, 8, 8, 5, 8, 5]   \n",
      "2     32.0     0.287104           0.455236  [5, 8, 5, 8, 5, 5]   \n",
      "11    54.0     0.266459           0.486889  [5, 8, 5, 8, 5, 8]   \n",
      "6     42.0     0.234388           0.376795  [5, 5, 5, 5, 5, 5]   \n",
      "19    64.0     0.222529           0.419185  [8, 5, 5, 5, 5, 5]   \n",
      "27    73.0     0.201266           0.355481  [8, 5, 5, 8, 8, 5]   \n",
      "4     36.0     0.197185           0.354099  [5, 8, 5, 5, 8, 8]   \n",
      "22    68.0     0.160939           0.306205  [5, 5, 5, 5, 8, 8]   \n",
      "21    67.0     0.136169           0.255686  [5, 8, 5, 8, 8, 8]   \n",
      "14    57.0     0.112141           0.197746  [5, 8, 5, 5, 8, 8]   \n",
      "25    71.0     0.068263           0.129976  [5, 5, 5, 5, 8, 8]   \n",
      "24    70.0     0.061234           0.116370  [8, 8, 8, 8, 5, 5]   \n",
      "9     51.0     0.060552           0.110940  [5, 5, 5, 8, 5, 5]   \n",
      "23    69.0     0.060069           0.115048  [5, 5, 5, 8, 8, 8]   \n",
      "15    59.0     0.018774           0.035788  [5, 8, 8, 8, 8, 8]   \n",
      "\n",
      "                                       Curriculum_OOO  \n",
      "12     [least, least, somewhat, somewhat, very, very]  \n",
      "26     [least, somewhat, somewhat, most, least, very]  \n",
      "18      [most, very, somewhat, least, very, somewhat]  \n",
      "13         [somewhat, least, most, very, very, least]  \n",
      "8      [most, least, somewhat, least, somewhat, very]  \n",
      "5      [least, somewhat, somewhat, most, least, very]  \n",
      "20     [least, somewhat, somewhat, most, least, very]  \n",
      "3      [somewhat, very, least, most, least, somewhat]  \n",
      "16         [least, least, least, least, least, least]  \n",
      "28          [somewhat, very, very, most, most, least]  \n",
      "10      [least, somewhat, most, somewhat, very, most]  \n",
      "0   [somewhat, somewhat, somewhat, very, somewhat,...  \n",
      "29      [very, somewhat, most, somewhat, least, very]  \n",
      "17     [least, somewhat, somewhat, most, least, very]  \n",
      "7         [somewhat, very, least, very, least, least]  \n",
      "1   [least, somewhat, somewhat, least, somewhat, l...  \n",
      "2      [least, somewhat, most, somewhat, most, least]  \n",
      "11               [very, very, very, very, very, very]  \n",
      "6     [least, least, least, somewhat, somewhat, most]  \n",
      "19          [very, least, least, least, least, least]  \n",
      "27      [somewhat, least, somewhat, very, most, very]  \n",
      "4      [least, somewhat, somewhat, most, least, very]  \n",
      "22     [somewhat, least, very, most, least, somewhat]  \n",
      "21     [least, somewhat, somewhat, very, most, least]  \n",
      "14     [least, somewhat, somewhat, most, least, very]  \n",
      "25         [somewhat, very, least, most, very, least]  \n",
      "24         [somewhat, very, most, least, least, very]  \n",
      "9         [most, very, somewhat, least, least, least]  \n",
      "23         [somewhat, most, very, least, most, least]  \n",
      "15     [somewhat, very, least, very, least, somewhat]  \n"
     ]
    }
   ],
   "source": [
    "# Calculate score of how well participants learn gnome sort\n",
    "performance_cohort=[]\n",
    "performance_list=[]\n",
    "p_half_mean_list=[]\n",
    "curriculum_all=[]\n",
    "curriculum_n_item=[]\n",
    "curriculum_ooo=[]\n",
    "\n",
    "\n",
    "# print(run_id_cohort1)\n",
    "Cohort1_all=pd.DataFrame(columns=['run_id','performance','performance_best5'])\n",
    "Cohort1_everyother=pd.DataFrame(columns=['run_id','performance'])\n",
    "for pp in run_id_cohort1_list:\n",
    "    data=pd.read_csv(path_cohort1+str(pp)+'.csv')\n",
    "    data_useful=data[['trial_type','time_elapsed', 'run_id','PROLIFIC_PID','STUDY_ID','stimulus','response','phase','question_order']]\n",
    "\n",
    "    index_crclm=data_useful[data_useful['trial_type'] == \"survey-multi-choice\"].index.to_numpy()\n",
    "    crclm=data_useful['response'][index_crclm]\n",
    "    # print(crclm.values)\n",
    "    json_str = crclm.values[0]\n",
    "    data = json.loads(json_str)\n",
    "\n",
    "    result = []\n",
    "    n_item=[]\n",
    "    OOO=[]\n",
    "    # \n",
    "    for i in range(0, len(data), 2): \n",
    "        item_key = f'Q{i}'\n",
    "        rating_key = f'Q{i+1}'\n",
    "        \n",
    "        # Get the number from \"X-item\" format\n",
    "        item_num = data[item_key].split('-')[0]\n",
    "        rating = data[rating_key]\n",
    "\n",
    "        # item_oor = data[item_key].split('-')[1] #out of order\n",
    "        # rating = data[rating_key]\n",
    "        \n",
    "        # Combine them in the desired format\n",
    "        result.append(f'{item_num}-{rating}')\n",
    "        n_item.append(item_num)\n",
    "        OOO.append(rating)\n",
    "\n",
    "    # curriculum_all.append(n_item)\n",
    "    curriculum_n_item.append(n_item)\n",
    "    curriculum_ooo.append(OOO)\n",
    "\n",
    "    quantile=0\n",
    "    performance=score(pp,n_test,path_cohort1,quantile)\n",
    "    performance_best5=score(pp,n_test,path_cohort1,0.5)\n",
    "    Cohort1_all.loc[len(Cohort1_all)] = [pp,performance,performance_best5]\n",
    "    performance_list.append(performance)\n",
    "    # performance_cohort.append([pp,performance])\n",
    "\n",
    "# print(curriculum_all)\n",
    "# Cohort1_all['Curriculum']=curriculum_all\n",
    "Cohort1_all['Curriculum_n_item']=curriculum_n_item\n",
    "Cohort1_all['Curriculum_OOO']=curriculum_ooo\n",
    "\n",
    "Cohort1_all = Cohort1_all.sort_values(by='performance',ascending=False)\n",
    "#swtich 72 and 63 because this is how it was the basis for the notes cohort2 saw, both 72 and 63 perfectly learned gnome sort (average p=1)\n",
    "row1 = Cohort1_all.index[Cohort1_all['run_id'] == 72.0].tolist()[0]\n",
    "row2 = Cohort1_all.index[Cohort1_all['run_id'] == 63.0].tolist()[0]\n",
    "temp = Cohort1_all.loc[row1].copy()\n",
    "Cohort1_all.loc[row1] = Cohort1_all.loc[row2].copy()\n",
    "Cohort1_all.loc[row2] = temp\n",
    "print(Cohort1_all)\n",
    "# Cohort1_all.plot(x=\"performance\", y=[\"performance_best5\"],\n",
    "#         kind=\"scatter\", figsize=(10, 10))\n",
    "\n",
    "run_id_c1_sorted_all_list=Cohort1_all['run_id'].values.tolist()\n",
    "run_id_c1_sorted_all_list=[int(x) for x in run_id_c1_sorted_all_list]\n",
    "Cohort1_everyother=Cohort1_all[::2]\n",
    "\n",
    "# Cohort1_everyother = Cohort1_all.iloc[[0, 1, 3, 5, 7,]]\n",
    "run_id_c1_sorted_evoth_list=Cohort1_everyother['run_id'].values.tolist()\n",
    "run_id_c1_sorted_evoth_list=[int(x) for x in run_id_c1_sorted_evoth_list]\n",
    "# print(run_id_c1_sorted_evoth_list)\n",
    "\n",
    "# plt.hist(performance_list, bins=20, color='skyblue', edgecolor='black')\n",
    "# plt.xlabel('Performance')\n",
    "# plt.ylabel('Frequency')\n",
    "   \n",
    "# print(Cohort1_everyother)\n",
    "Cohort1_all.to_csv(os.path.join(path_up,'Cohort1_all.csv'))\n",
    "Cohort1_everyother.to_csv(os.path.join(path_up,'Cohort1_everyother.csv'))\n",
    "\n",
    "\n",
    "# crclm=crclm.split(\",\")\n",
    "\n",
    "# score(44,10,path_cohort1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    run_id  performance  performance_best5   Curriculum_n_item  \\\n",
      "12    55.0     1.000000           1.000000  [5, 8, 5, 8, 5, 8]   \n",
      "26    63.0     1.000000           1.000000  [5, 8, 5, 5, 8, 8]   \n",
      "18    72.0     1.000000           1.000000  [5, 5, 5, 5, 8, 8]   \n",
      "13    56.0     0.942081           1.000000  [5, 8, 5, 8, 5, 8]   \n",
      "8     44.0     0.928959           1.000000  [5, 5, 5, 8, 8, 5]   \n",
      "5     37.0     0.905773           1.000000  [5, 8, 5, 5, 8, 8]   \n",
      "20    66.0     0.888285           1.000000  [5, 8, 5, 5, 8, 8]   \n",
      "3     35.0     0.859265           1.000000  [5, 8, 5, 5, 8, 8]   \n",
      "16    60.0     0.847537           1.000000  [5, 5, 5, 5, 5, 5]   \n",
      "28    75.0     0.622118           1.000000  [5, 8, 5, 8, 5, 8]   \n",
      "10    52.0     0.533691           0.833552  [5, 5, 5, 8, 8, 8]   \n",
      "0     30.0     0.503541           0.780500  [5, 8, 8, 8, 8, 8]   \n",
      "29    76.0     0.457299           0.708104  [5, 8, 5, 8, 5, 5]   \n",
      "17    62.0     0.429623           0.740314  [5, 8, 5, 5, 8, 8]   \n",
      "7     43.0     0.303902           0.503000  [5, 5, 5, 8, 8, 8]   \n",
      "1     31.0     0.296726           0.471601  [5, 8, 8, 5, 8, 5]   \n",
      "2     32.0     0.287104           0.455236  [5, 8, 5, 8, 5, 5]   \n",
      "11    54.0     0.266459           0.486889  [5, 8, 5, 8, 5, 8]   \n",
      "6     42.0     0.234388           0.376795  [5, 5, 5, 5, 5, 5]   \n",
      "19    64.0     0.222529           0.419185  [8, 5, 5, 5, 5, 5]   \n",
      "27    73.0     0.201266           0.355481  [8, 5, 5, 8, 8, 5]   \n",
      "4     36.0     0.197185           0.354099  [5, 8, 5, 5, 8, 8]   \n",
      "22    68.0     0.160939           0.306205  [5, 5, 5, 5, 8, 8]   \n",
      "21    67.0     0.136169           0.255686  [5, 8, 5, 8, 8, 8]   \n",
      "14    57.0     0.112141           0.197746  [5, 8, 5, 5, 8, 8]   \n",
      "25    71.0     0.068263           0.129976  [5, 5, 5, 5, 8, 8]   \n",
      "24    70.0     0.061234           0.116370  [8, 8, 8, 8, 5, 5]   \n",
      "9     51.0     0.060552           0.110940  [5, 5, 5, 8, 5, 5]   \n",
      "23    69.0     0.060069           0.115048  [5, 5, 5, 8, 8, 8]   \n",
      "15    59.0     0.018774           0.035788  [5, 8, 8, 8, 8, 8]   \n",
      "\n",
      "                                       Curriculum_OOO  \n",
      "12     [least, least, somewhat, somewhat, very, very]  \n",
      "26     [least, somewhat, somewhat, most, least, very]  \n",
      "18      [most, very, somewhat, least, very, somewhat]  \n",
      "13         [somewhat, least, most, very, very, least]  \n",
      "8      [most, least, somewhat, least, somewhat, very]  \n",
      "5      [least, somewhat, somewhat, most, least, very]  \n",
      "20     [least, somewhat, somewhat, most, least, very]  \n",
      "3      [somewhat, very, least, most, least, somewhat]  \n",
      "16         [least, least, least, least, least, least]  \n",
      "28          [somewhat, very, very, most, most, least]  \n",
      "10      [least, somewhat, most, somewhat, very, most]  \n",
      "0   [somewhat, somewhat, somewhat, very, somewhat,...  \n",
      "29      [very, somewhat, most, somewhat, least, very]  \n",
      "17     [least, somewhat, somewhat, most, least, very]  \n",
      "7         [somewhat, very, least, very, least, least]  \n",
      "1   [least, somewhat, somewhat, least, somewhat, l...  \n",
      "2      [least, somewhat, most, somewhat, most, least]  \n",
      "11               [very, very, very, very, very, very]  \n",
      "6     [least, least, least, somewhat, somewhat, most]  \n",
      "19          [very, least, least, least, least, least]  \n",
      "27      [somewhat, least, somewhat, very, most, very]  \n",
      "4      [least, somewhat, somewhat, most, least, very]  \n",
      "22     [somewhat, least, very, most, least, somewhat]  \n",
      "21     [least, somewhat, somewhat, very, most, least]  \n",
      "14     [least, somewhat, somewhat, most, least, very]  \n",
      "25         [somewhat, very, least, most, very, least]  \n",
      "24         [somewhat, very, most, least, least, very]  \n",
      "9         [most, very, somewhat, least, least, least]  \n",
      "23         [somewhat, most, very, least, most, least]  \n",
      "15     [somewhat, very, least, very, least, somewhat]  \n",
      "    run_id  performance  performance_best5   Curriculum_n_item  \\\n",
      "12    55.0     1.000000           1.000000  [5, 8, 5, 8, 5, 8]   \n",
      "26    63.0     1.000000           1.000000  [5, 8, 5, 5, 8, 8]   \n",
      "18    72.0     1.000000           1.000000  [5, 5, 5, 5, 8, 8]   \n",
      "13    56.0     0.942081           1.000000  [5, 8, 5, 8, 5, 8]   \n",
      "8     44.0     0.928959           1.000000  [5, 5, 5, 8, 8, 5]   \n",
      "5     37.0     0.905773           1.000000  [5, 8, 5, 5, 8, 8]   \n",
      "20    66.0     0.888285           1.000000  [5, 8, 5, 5, 8, 8]   \n",
      "3     35.0     0.859265           1.000000  [5, 8, 5, 5, 8, 8]   \n",
      "16    60.0     0.847537           1.000000  [5, 5, 5, 5, 5, 5]   \n",
      "28    75.0     0.622118           1.000000  [5, 8, 5, 8, 5, 8]   \n",
      "10    52.0     0.533691           0.833552  [5, 5, 5, 8, 8, 8]   \n",
      "0     30.0     0.503541           0.780500  [5, 8, 8, 8, 8, 8]   \n",
      "29    76.0     0.457299           0.708104  [5, 8, 5, 8, 5, 5]   \n",
      "17    62.0     0.429623           0.740314  [5, 8, 5, 5, 8, 8]   \n",
      "7     43.0     0.303902           0.503000  [5, 5, 5, 8, 8, 8]   \n",
      "1     31.0     0.296726           0.471601  [5, 8, 8, 5, 8, 5]   \n",
      "2     32.0     0.287104           0.455236  [5, 8, 5, 8, 5, 5]   \n",
      "11    54.0     0.266459           0.486889  [5, 8, 5, 8, 5, 8]   \n",
      "6     70.0     0.061234           0.116370  [8, 8, 8, 8, 5, 5]   \n",
      "19    64.0     0.222529           0.419185  [8, 5, 5, 5, 5, 5]   \n",
      "27    73.0     0.201266           0.355481  [8, 5, 5, 8, 8, 5]   \n",
      "4     36.0     0.197185           0.354099  [5, 8, 5, 5, 8, 8]   \n",
      "22    68.0     0.160939           0.306205  [5, 5, 5, 5, 8, 8]   \n",
      "21    67.0     0.136169           0.255686  [5, 8, 5, 8, 8, 8]   \n",
      "14    57.0     0.112141           0.197746  [5, 8, 5, 5, 8, 8]   \n",
      "25    71.0     0.068263           0.129976  [5, 5, 5, 5, 8, 8]   \n",
      "24    42.0     0.234388           0.376795  [5, 5, 5, 5, 5, 5]   \n",
      "9     51.0     0.060552           0.110940  [5, 5, 5, 8, 5, 5]   \n",
      "23    69.0     0.060069           0.115048  [5, 5, 5, 8, 8, 8]   \n",
      "15    59.0     0.018774           0.035788  [5, 8, 8, 8, 8, 8]   \n",
      "\n",
      "                                       Curriculum_OOO  \n",
      "12     [least, least, somewhat, somewhat, very, very]  \n",
      "26     [least, somewhat, somewhat, most, least, very]  \n",
      "18      [most, very, somewhat, least, very, somewhat]  \n",
      "13         [somewhat, least, most, very, very, least]  \n",
      "8      [most, least, somewhat, least, somewhat, very]  \n",
      "5      [least, somewhat, somewhat, most, least, very]  \n",
      "20     [least, somewhat, somewhat, most, least, very]  \n",
      "3      [somewhat, very, least, most, least, somewhat]  \n",
      "16         [least, least, least, least, least, least]  \n",
      "28          [somewhat, very, very, most, most, least]  \n",
      "10      [least, somewhat, most, somewhat, very, most]  \n",
      "0   [somewhat, somewhat, somewhat, very, somewhat,...  \n",
      "29      [very, somewhat, most, somewhat, least, very]  \n",
      "17     [least, somewhat, somewhat, most, least, very]  \n",
      "7         [somewhat, very, least, very, least, least]  \n",
      "1   [least, somewhat, somewhat, least, somewhat, l...  \n",
      "2      [least, somewhat, most, somewhat, most, least]  \n",
      "11               [very, very, very, very, very, very]  \n",
      "6          [somewhat, very, most, least, least, very]  \n",
      "19          [very, least, least, least, least, least]  \n",
      "27      [somewhat, least, somewhat, very, most, very]  \n",
      "4      [least, somewhat, somewhat, most, least, very]  \n",
      "22     [somewhat, least, very, most, least, somewhat]  \n",
      "21     [least, somewhat, somewhat, very, most, least]  \n",
      "14     [least, somewhat, somewhat, most, least, very]  \n",
      "25         [somewhat, very, least, most, very, least]  \n",
      "24    [least, least, least, somewhat, somewhat, most]  \n",
      "9         [most, very, somewhat, least, least, least]  \n",
      "23         [somewhat, most, very, least, most, least]  \n",
      "15     [somewhat, very, least, very, least, somewhat]  \n"
     ]
    }
   ],
   "source": [
    "Cohort1_all = Cohort1_all.sort_values(by='performance',ascending=False)\n",
    "print(Cohort1_all)\n",
    "row1 = Cohort1_all.index[Cohort1_all['run_id'] == 72.0].tolist()[0]\n",
    "# print(row1)\n",
    "row2 = Cohort1_all.index[Cohort1_all['run_id'] == 63.0].tolist()[0]\n",
    "Cohort1_all.iloc[18], Cohort1_all.iloc[26] = Cohort1_all.iloc[26].copy(), Cohort1_all.iloc[18].copy()\n",
    "print(Cohort1_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    run_id                                              Notes\n",
      "0       55  Check if it is moving left to right. They chec...\n",
      "1       63  KEYS TO OMGNE SORT<br>If a pair changes places...\n",
      "2       72  Step 1: Designate the leftmost object as Objec...\n",
      "3       56  Starting with the left-most block, click on th...\n",
      "4       44  Start by comparing the first two blocks. Then ...\n",
      "5       37  COMPARE TWO ITEMS UNTIL THEY STOP ROTATING, ON...\n",
      "6       66  Continue to swap pieces until you have put the...\n",
      "7       35  as you sort the gold blocks, compare them to t...\n",
      "8       60  Click on the blocks in pairs from left to righ...\n",
      "9       75  Select 2 blocks. It is recommended to start pl...\n",
      "10      52  Instead of using a compare the first block to ...\n",
      "11      30             check on patterns and learn to do them\n",
      "12      76  Start left from right and if there is a change...\n",
      "13      62  Select items starting at the left and then to ...\n",
      "14      43  Start with the first block and move it to the ...\n",
      "15      31  compare each block with next if it swaps the r...\n",
      "16      32   compare each with precious block after each swap\n",
      "17      54  Start on the first block and click the second....\n",
      "18      42  Select 2 objects beside each other and see if ...\n",
      "19      64       go from left to right selecting 2 at a time.\n",
      "20      73  Sort the heavy first by selecting and moving t...\n",
      "21      36  Quick Guide to Identifying Omgne Sort Patterns...\n",
      "22      68  Hi Students. look out for the number of swaps ...\n",
      "23      67  Hi there, for every 5 item arranged, if you so...\n",
      "24      57  The Omgne Sort patterns makes it easy for bett...\n",
      "25      71  Hello Folks, don't forget to keep track of how...\n",
      "26      70  Hi There, look out for the pattern with the le...\n",
      "27      51  move the animals randomly until they dont swit...\n",
      "28      69  Hi There, the least number of swaps has the te...\n",
      "29      59      Try your best and click the ones to move them\n",
      "    run_id                                              Notes\n",
      "0       55  Check if it is moving left to right. They chec...\n",
      "1       72  Step 1: Designate the leftmost object as Objec...\n",
      "2       44  Start by comparing the first two blocks. Then ...\n",
      "3       66  Continue to swap pieces until you have put the...\n",
      "4       60  Click on the blocks in pairs from left to righ...\n",
      "5       52  Instead of using a compare the first block to ...\n",
      "6       76  Start left from right and if there is a change...\n",
      "7       43  Start with the first block and move it to the ...\n",
      "8       32   compare each with precious block after each swap\n",
      "9       42  Select 2 objects beside each other and see if ...\n",
      "10      73  Sort the heavy first by selecting and moving t...\n",
      "11      68  Hi Students. look out for the number of swaps ...\n",
      "12      57  The Omgne Sort patterns makes it easy for bett...\n",
      "13      70  Hi There, look out for the pattern with the le...\n",
      "14      69  Hi There, the least number of swaps has the te...\n"
     ]
    }
   ],
   "source": [
    "ii=0\n",
    "ling_all_cohort1=[]\n",
    "run_id_sorted=[]\n",
    "for run_id in run_id_c1_sorted_all_list:\n",
    "    \n",
    "    data=pd.read_csv(path_cohort1+str(run_id)+'.csv')\n",
    "    data_useful=data[['trial_type','time_elapsed', 'run_id','PROLIFIC_PID','STUDY_ID','stimulus','response','phase','question_order']]\n",
    "    index_ling=data_useful[data_useful['trial_type'] == \"survey-text\"].index.to_numpy()\n",
    "    ling=str(list(data_useful['response'][index_ling]))\n",
    "    ling=ling[9:-4]\n",
    "    ling=ling.replace(\"\\\\\\\\n\", \"<br>\") \n",
    "    ling=ling.replace(\"\\\\\", \"\")\n",
    "    ling_all_cohort1.append(ling)\n",
    "    run_id_sorted.append(run_id)\n",
    "\n",
    "    if ii==0:\n",
    "        initial_data = {'run_id': [run_id], \n",
    "                'Notes': [ling]}\n",
    "        ling_df_all = pd.DataFrame(initial_data, columns = ['run_id', 'Notes'])\n",
    "    else:\n",
    "        ling_df_all.loc[len(ling_df_all)] = [run_id, ling]\n",
    "\n",
    "    ii+=1\n",
    "\n",
    "print(ling_df_all)\n",
    "# ling_id_df.to_csv(os.path.join(path_up,'Note_cohort1.csv'))\n",
    "\n",
    "\n",
    "ii=0\n",
    "ling_all_cohort1=[]\n",
    "run_id_sorted=[]\n",
    "for run_id in run_id_c1_sorted_evoth_list:\n",
    "    \n",
    "    data=pd.read_csv(path_cohort1+str(run_id)+'.csv')\n",
    "    data_useful=data[['trial_type','time_elapsed', 'run_id','PROLIFIC_PID','STUDY_ID','stimulus','response','phase','question_order']]\n",
    "    index_ling=data_useful[data_useful['trial_type'] == \"survey-text\"].index.to_numpy()\n",
    "    ling=str(list(data_useful['response'][index_ling]))\n",
    "    ling=ling[9:-4]\n",
    "    ling=ling.replace(\"\\\\\\\\n\", \"<br>\") \n",
    "    ling=ling.replace(\"\\\\\", \"\")\n",
    "    ling_all_cohort1.append(ling)\n",
    "    run_id_sorted.append(run_id)\n",
    "\n",
    "    if ii==0:\n",
    "        initial_data = {'run_id': [run_id], \n",
    "                'Notes': [ling]}\n",
    "        ling_df_everyother = pd.DataFrame(initial_data, columns = ['run_id', 'Notes'])\n",
    "    else:\n",
    "        ling_df_everyother.loc[len(ling_df_everyother)] = [run_id, ling]\n",
    "\n",
    "    ii+=1\n",
    "\n",
    "print(ling_df_everyother)\n",
    "# ling_id_df.to_csv(os.path.join(path_up,'Note_cohort1.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#every other notes\n",
    "# ling_id_df_half=ling_id_df.iloc[::2, :]\n",
    "# ling_id_df_half=ling_id_df\n",
    "# ling_id_df_half.to_csv(os.path.join(path_up,'Note_cohort1_half.csv'))\n",
    "# ling_id_df_half=ling_id_df_half.groupby(ling_id_df_half.index // 2).first()\n",
    "# ling_id_df_half=ling_id_df_half[['Notes']]\n",
    "ling_all_list=ling_df_all['Notes'].tolist()\n",
    "ling_everyother_list=ling_df_everyother['Notes'].tolist()\n",
    "# ling_id_df_half.index/22\n",
    "# print(len(ling_all_list))\n",
    "# print(len(ling_everyother_list))\n",
    "\n",
    "Cohort1_all['Notes'] = ling_all_list\n",
    "Cohort1_all.to_csv(os.path.join(path_up,'Cohort1_all.csv'))\n",
    "\n",
    "Cohort1_everyother['Notes'] = ling_everyother_list\n",
    "Cohort1_everyother.to_csv(os.path.join(path_up,'Cohort1_everyother.csv'))\n",
    "# ling_id_df_half"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analayzing experiments with note rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get legit run_id and pid\n",
    "pid_cohort2_total=pid_from_demographic('Cohort2_Demographic.csv','pid_Cohort2.csv')\n",
    "path_cohort2='C:/Users/guoqi/GITHUB_QGUO/Gold_Block_Data_Analysis/Data/Pilot/Cohort2_30Participants/'\n",
    "ids_cohort2=ids(pid_cohort2_total,path_cohort2,['PROLIFIC_PID','phase','presented_choices'])\n",
    "run_id_cohort2=ids_cohort2['run_id']\n",
    "run_id_cohort2_list=run_id_cohort2.values.tolist()\n",
    "n_test=6\n",
    "# print(ids_cohort2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    run_id  performance\n",
      "16    31.0     1.000000\n",
      "6     17.0     1.000000\n",
      "8     19.0     1.000000\n",
      "10    22.0     1.000000\n",
      "11    23.0     1.000000\n",
      "14    29.0     0.952169\n",
      "5     16.0     0.840812\n",
      "1     12.0     0.798731\n",
      "13    28.0     0.786492\n",
      "22    41.0     0.759179\n",
      "2     13.0     0.682692\n",
      "12    26.0     0.622149\n",
      "0     11.0     0.616173\n",
      "26    45.0     0.525715\n",
      "21    40.0     0.476655\n",
      "19    36.0     0.474135\n",
      "4     15.0     0.441624\n",
      "3     14.0     0.337132\n",
      "18    33.0     0.266227\n",
      "28     9.0     0.237020\n",
      "20    38.0     0.230552\n",
      "25    44.0     0.210880\n",
      "27    46.0     0.166286\n",
      "15    30.0     0.054819\n",
      "9     20.0     0.040429\n",
      "24    43.0     0.039044\n",
      "23    42.0     0.019571\n",
      "7     18.0     0.011111\n",
      "17    32.0     0.003326\n",
      "    run_id  performance\n",
      "16    31.0     1.000000\n",
      "8     19.0     1.000000\n",
      "11    23.0     1.000000\n",
      "5     16.0     0.840812\n",
      "13    28.0     0.786492\n",
      "2     13.0     0.682692\n",
      "0     11.0     0.616173\n",
      "21    40.0     0.476655\n",
      "4     15.0     0.441624\n",
      "18    33.0     0.266227\n",
      "20    38.0     0.230552\n",
      "27    46.0     0.166286\n",
      "9     20.0     0.040429\n",
      "23    42.0     0.019571\n",
      "17    32.0     0.003326\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate score of how well participants learn gnome sort\n",
    "performance_cohort2=[]\n",
    "performance1_list=[]\n",
    "\n",
    "Cohort2_all=pd.DataFrame(columns=['run_id','performance'])\n",
    "Cohort2_everyother=pd.DataFrame(columns=['run_id','performance'])\n",
    "for pp in run_id_cohort2_list:\n",
    "    data=pd.read_csv(path_cohort2+str(pp)+'.csv')\n",
    "    data_useful=data[['trial_type','time_elapsed', 'run_id','PROLIFIC_PID','STUDY_ID','stimulus','response','phase','question_order']]\n",
    "        \n",
    "    quantile=0\n",
    "    n_test=6\n",
    "    # print(pp)\n",
    "    performance=score(pp,n_test,path_cohort2,quantile)\n",
    "    Cohort2_all.loc[len(Cohort2_all)] = [pp,performance]\n",
    "    performance1_list.append(performance)\n",
    "    performance_cohort2.append([pp,performance])\n",
    "    \n",
    "Cohort2_all = Cohort2_all.sort_values(by='performance',ascending=False)\n",
    "print(Cohort2_all)\n",
    "Cohort2_everyother=Cohort2_all[::2]\n",
    "\n",
    "plt.hist(performance1_list, bins=20, color='skyblue', edgecolor='black')\n",
    "   \n",
    "print(Cohort2_everyother)\n",
    "Cohort2_all.to_csv(os.path.join(path_up,'Cohort2_all.csv'))\n",
    "Cohort2_everyother.to_csv(os.path.join(path_up,'Cohort2_everyother.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'go from left to right selecting 2 at a time.' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 35\u001b[0m\n\u001b[0;32m     32\u001b[0m indices_two_notes\u001b[38;5;241m=\u001b[39m[]\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m choice \u001b[38;5;129;01min\u001b[39;00m choices:\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;66;03m# print(choice)\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m     index_note\u001b[38;5;241m=\u001b[39mling_everyother_list\u001b[38;5;241m.\u001b[39mindex(choice)\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;66;03m# pos1 = Cohort1_all[Cohort1_all['Notes'] == choice].index[0]\u001b[39;00m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;66;03m# print(index_note)\u001b[39;00m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;66;03m# ling_id_df_half.tolist()\u001b[39;00m\n\u001b[0;32m     39\u001b[0m     indices_two_notes\u001b[38;5;241m.\u001b[39mappend(index_note)\n",
      "\u001b[1;31mValueError\u001b[0m: 'go from left to right selecting 2 at a time.' is not in list"
     ]
    }
   ],
   "source": [
    "#Preprocess for Bradley-Terry Model\n",
    "\n",
    "matrix_rating_total=np.zeros((15,15))\n",
    "for run_id in run_id_cohort2_list:\n",
    "    matrix_rating=np.zeros((15,15))\n",
    "    # print(\"run_id is\",run_id)\n",
    "    # data = pd.read_csv(csv) \n",
    "    data=pd.read_csv(path_cohort2+str(run_id)+'.csv')\n",
    "    data_useful=data[['trial_type','time_elapsed', 'run_id','PROLIFIC_PID','STUDY_ID','stimulus','response','phase','presented_choices']]\n",
    "    # print(data_useful)\n",
    "    \n",
    "\n",
    "    for ii in range(0,14):\n",
    "        indices_rating=data_useful[data_useful['phase'] == \"Note Comparison\"].index.to_numpy()\n",
    "        if ii==5 and data_useful['response'][min(indices_rating)+(ii*2)+1]==1:\n",
    "            print(run_id,\"Did not pass attention check\")\n",
    "        if ii==9 and data_useful['response'][min(indices_rating)+(ii*2)+1]==0:    \n",
    "            print(run_id,\"Did not pass attention check\")\n",
    "\n",
    "        if ii!=5 and ii!=9:\n",
    "            # print(indices_rating)\n",
    "            index_choices=min(indices_rating)+(ii*2)\n",
    "            index_betterone=index_choices+1\n",
    "            # print(index_choices)\n",
    "            # print(index_betterone)\n",
    "            choices=data_useful['presented_choices'][min(indices_rating)+(ii*2)].split('\",\"')\n",
    "            # print(len(choices))\n",
    "            choices = [s.replace('[\"', '') for s in choices]  \n",
    "            choices = [s.replace('\"]', '') for s in choices]  \n",
    "            choices = [s.replace('\\\\', '') for s in choices]  \n",
    "\n",
    "            indices_two_notes=[]\n",
    "            for choice in choices:\n",
    "                # print(choice)\n",
    "                index_note=ling_everyother_list.index(choice)\n",
    "                # pos1 = Cohort1_all[Cohort1_all['Notes'] == choice].index[0]\n",
    "                # print(index_note)\n",
    "                # ling_id_df_half.tolist()\n",
    "                indices_two_notes.append(index_note)\n",
    "                run_id_note=run_id_sorted[index_note]\n",
    "                # run_id_note=Cohort1_all.loc[pos1,'run_id']\n",
    "\n",
    "\n",
    "                # print(index_note)\n",
    "                # print(\"length\")\n",
    "                # print(min(indices_rating)+(ii*2)+1)\n",
    "                # print(len(data_useful))\n",
    "            if (min(indices_rating)+(ii*2)+2)>len(data_useful):\n",
    "                print('Rating Skipped')\n",
    "            else:\n",
    "                # print(\"indices\",indices_two_notes)\n",
    "                better_one=data_useful['response'][min(indices_rating)+(ii*2)+1]\n",
    "                a=indices_two_notes[0]\n",
    "                b=indices_two_notes[1]\n",
    "                if better_one==0:\n",
    "                    matrix_rating[a][b]+=1\n",
    "                else:\n",
    "                    matrix_rating[b][a]+=1\n",
    "    matrix_rating_total=matrix_rating_total+matrix_rating\n",
    "print(matrix_rating_total)\n",
    "# sum(matrix_rating_total)\n",
    "print(np.matrix(matrix_rating_total).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.63983316 1.04331568 0.65981147 2.27037535]\n"
     ]
    }
   ],
   "source": [
    "#Validating Bradley-Terry model based on worked example on wikipedia\n",
    "matrix_example=[[0,2,0,1],[3,0,5,0],[0,3,0,1],[4,0,3,0]]\n",
    "matrix_example_df=pd.DataFrame(matrix_example)\n",
    "\n",
    "def BT(matrix_win_lose):\n",
    "    p_list_converge=[]\n",
    "    p_list=np.ones(len(matrix_win_lose))\n",
    "    for jj in range(100):\n",
    "        multi_all=1\n",
    "        for ii in range(len(p_list)):\n",
    "            wij=matrix_win_lose.iloc[ii]\n",
    "            wji=matrix_win_lose[ii]\n",
    "            pij_nom=p_list/(p_list[ii]+p_list)\n",
    "            pij_den=1/(p_list[ii]+p_list)\n",
    "            p_list[ii]=sum(wij*pij_nom)/sum(wji*pij_den)\n",
    "            multi_all*=p_list[ii]\n",
    "        geo_mean=multi_all**(1/len(p_list))\n",
    "        p_list=p_list/geo_mean\n",
    "        p_list_converge.append(p_list)\n",
    "        if jj>0 and abs(sum(p_list_converge[jj])-sum(p_list_converge[jj-1]))<0.00001:\n",
    "            break\n",
    "    return p_list\n",
    "# print(p_list_converge)\n",
    "print(BT(matrix_example_df))\n",
    "# print(geo_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6214567  1.74906992 0.92456393 1.75471508 1.43005868 1.07654789\n",
      " 1.0520941  1.44617014 1.06302724 0.54954727 0.9392574  0.56717607\n",
      " 0.91677382 0.91591667 0.92641819]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\guoqi\\AppData\\Local\\Temp\\ipykernel_24836\\237993971.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Cohort1_everyother['Note rating'] = ranking_BT_everyother\n"
     ]
    }
   ],
   "source": [
    "ranking_BT_everyother=BT(pd.DataFrame(matrix_rating_total))\n",
    "print(BT(pd.DataFrame(matrix_rating_total)))\n",
    "Cohort1_everyother['Note rating'] = ranking_BT_everyother\n",
    "\n",
    "Cohort1_everyother.to_csv(os.path.join(path_up,'Cohort1_everyother.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
